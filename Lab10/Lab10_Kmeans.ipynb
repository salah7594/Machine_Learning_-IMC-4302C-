{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 10: K-means Clustering (Unsupervised Learning) \n",
    "\n",
    "In this session we will try to understand how K-means clustering algorithm works. It is an unsupervised learning algorithm that allows us to detect pattern or groups on unlabeled data. This algorithm start with initializing a given number K of centroid and it assign each point to the nearest centroid. After assigning all point, each centroid updated as the centroid (mean) of points that have same label as the centroid. Then, we reassign point according to the new centroids. We repeat these steps until the algorithm converge and centroids become stable (don't move anymore)\n",
    "\n",
    "In the first part, we will implement the K-means algorithm. Then, we will see the effect of centroids  initialization and how dramatically it could affect output clusters. In last part, we will see \"elbow\" method used for selecting a suitable number of cluster K to use.\n",
    "\n",
    "### Implement K-means\n",
    "<font color=\"blue\">**Question 1: **</font> \n",
    "- Load data from \"clusters_3.txt\" file. (use [loadtxt](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.loadtxt.html) function from numpy library).\n",
    "- Implement the \"euclidean_dist\" function that calculate the euclidean distance (norm L2: square root of sum of square) between two vectors.\n",
    "- Implement the cluster assignment step (inner for loop with counter \"i\"). It consist to assign each point to the nearest cluster centroid. Put the result in \"clust_x\" array that contains the cluster Id for each point (\"m\" points).    \n",
    "**Hint:** You could use \"euclidean_dist\" function to calculate distances between each point and all the centroids.\n",
    "- Implement update centroids step (inner for loop with counter \"c\"). It consist to calculate new centroid as the mean of all point that are assigned to its cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "# load data\n",
    "X =     # ** your code here** \n",
    "print(\"The size of data is:\",X.shape)\n",
    "m=X.shape[0]\n",
    "\n",
    "# number of cluster\n",
    "K = 3\n",
    "print(\"Number of cluster to find is:\",K)\n",
    "\n",
    "# Intialize centroids and cluster assignment\n",
    "#centroid=np.array([[4,5],[4,3],[0,5]],dtype=float)\n",
    "centroid=np.array([[4,0],[4,3],[0,5]],dtype=float)\n",
    "clust_x=np.zeros((m,))\n",
    "centroid_hist=[np.copy(centroid)]\n",
    "\n",
    "# euclidean distance\n",
    "def euclidean_dist(x1,x2):\n",
    "    # ** your code here** \n",
    "    return 0\n",
    "\n",
    "# K-means clustering algorithm\n",
    "def K_means(X,clust_x,centroid,centroid_hist=[],hist=False,max_iter=10):\n",
    "    k = centroid.shape[0]\n",
    "    m = X.shape[0]\n",
    "\n",
    "    for iter_ in range(max_iter):\n",
    "        # Cluster assignment step\n",
    "        for i in range(m):\n",
    "            # ** your code here** \n",
    "            clust_x[i] =  # ** your code here** \n",
    "        # Update centroids step\n",
    "        for c in range(k):\n",
    "            centroid[c,:] = # ** your code here**\n",
    "\n",
    "        if (hist):\n",
    "            centroid_hist.append(np.copy(centroid))\n",
    "    if (hist):\n",
    "        return centroid,centroid_hist,clust_x\n",
    "    return centroid,clust_x\n",
    "\n",
    "centroid,centroid_hist,clust_x = K_means(X,clust_x,centroid,centroid_hist,hist=True)\n",
    "\n",
    "# visualize clusters and centroids    \n",
    "plt.figure(\"K-means steps\",figsize=(7,5))\n",
    "plt.scatter(X[clust_x==0,0],X[clust_x==0,1],color=\"blue\",marker='o',facecolors='none')\n",
    "plt.scatter(X[clust_x==1,0],X[clust_x==1,1],color=\"red\",marker='o',facecolors='none')\n",
    "plt.scatter(X[clust_x==2,0],X[clust_x==2,1],color=\"green\",marker='o',facecolors='none')\n",
    "plt.scatter(centroid[:,0],centroid[:,1],color=\"k\",marker='*',s=100)\n",
    "for i in range(len(centroid_hist)-1):\n",
    "    plt.scatter(centroid_hist[i][:,0],centroid_hist[i][:,1],color=\"k\",marker='*',facecolors='none')\n",
    "    #plt.plot([centroid_hist[i][:,0],centroid_hist[i+1][:,0]],[centroid_hist[i][:,1],centroid_hist[i+1][:,1]],'k--',linewidth=1)\n",
    "    plt.quiver(centroid_hist[i][:,0],centroid_hist[i][:,1],centroid_hist[i+1][:,0]-centroid_hist[i][:,0],centroid_hist[i+1][:,1]-centroid_hist[i][:,1],width=.003,color='k',scale=1,scale_units='xy',angles='xy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random initialization of centroids\n",
    "\n",
    "We see that the final clustering result depend a lot of used initial centroids. It could also change a lot even with few modification in the centroid initialization. Hence, We will randomly initialize centroids and run K-means algorithm several time then we will take the best run. In order to compare different runs and select the best one we calculate a error function that reflect how well is the final clustering. This error is equal to the sum of square error (euclidean distance) between all point and their corresponding cluster centroid. It is given by:\n",
    "$$cluster\\_error(clust\\_x,centroid)=\\frac{1}{m}\\sum_{i=1}^m \\left \\| x^{(i)}-centroid(x^{(i)}) \\right \\|^2$$\n",
    "where:  $\\left \\| x \\right \\|^2=\\sum_{j=1}^nx_j^2$ \n",
    "\n",
    "<font color=\"blue\">**Question 2: **</font> \n",
    "- Initialize the minimum error \"Jmin\" with +infinity.  \n",
    "**Hint:** You could use numpy.inf value.\n",
    "- Initialize \"centroid\" with random K point from original data \"X\".  \n",
    "**Hint:** You could generate a [random permutation](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.random.permutation.html) vector of size \"m\". Then, extract from it first K element to index lines of matrix \"X\" and put results in \"centroid\" variable.\n",
    "- Calculate the error function \"J\" according to the equation given above.\n",
    "- In \"if (J < Jmin)\" statement assign the suitable value for \"Jmin\", \"centroid_min\" and \"clust_x_min\" variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize some variable\n",
    "centroid = np.zeros((K,X.shape[1]))\n",
    "clust_x = np.zeros((m,),dtype=int)\n",
    "centroid_min = np.zeros((K,X.shape[1]))\n",
    "clust_x_min = np.zeros((m,),dtype=int)\n",
    "Jmin =  # ** your code here** \n",
    "\n",
    "# K-means with random initialization and  multiple runs\n",
    "def K_means_multi_run(X,centroid,clust_x,centroid_min,clust_x_min,Jmin,monte_carlo=100):\n",
    "    m = X.shape[0]\n",
    "    k = centroid.shape[0]\n",
    "    for p in range(monte_carlo):\n",
    "        # ** your code here** \n",
    "        centroid =  # ** your code here** \n",
    "        centroid,clust_x = K_means(X,clust_x,centroid)\n",
    "        # error function\n",
    "        J =   # ** your code here** \n",
    "        if(J<Jmin):\n",
    "            Jmin =  # ** your code here** \n",
    "            centroid_min =  # ** your code here** \n",
    "            clust_x_min =   # ** your code here** \n",
    "    return centroid_min,clust_x_min,Jmin\n",
    "\n",
    "centroid_min,clust_x_min,Jmin = K_means_multi_run(X,centroid,clust_x,centroid_min,clust_x_min,Jmin)\n",
    "print(\"The minimum error is:\",Jmin)\n",
    "print(\"it was get for the following cluster centroids:\\n\",centroid_min)\n",
    "\n",
    "# plot final clusters and centroids\n",
    "plt.figure(\"K-means with multiple runs\",figsize=(7,5))\n",
    "plt.scatter(X[clust_x_min==0,0],X[clust_x_min==0,1],color=\"blue\",marker='o',facecolors='none')\n",
    "plt.scatter(X[clust_x_min==1,0],X[clust_x_min==1,1],color=\"red\",marker='o',facecolors='none')\n",
    "plt.scatter(X[clust_x_min==2,0],X[clust_x_min==2,1],color=\"green\",marker='o',facecolors='none')\n",
    "plt.scatter(centroid_min[:,0],centroid_min[:,1],color=\"black\",marker='*',s=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the number of cluster K\n",
    "We are in the case of unsupervised learning and we don't known labels or number cluster in our data. However, K-mean clustering algorithm need to known in advance the number of cluster K. Hence, we will run K-means for different number of cluster K and we will choose the number that reasonable performance and error. \n",
    "\n",
    "<font color=\"blue\">**Question 3: **</font> \n",
    "- Use (make_bolbs)[http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html] function from sklearn library to generate some random clusters. Use the following argument:  \n",
    "n_samples=1000, n_features=2, centers=7, cluster_std=1.2 and random_state=0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "\n",
    "# generate clusters\n",
    "X, y =  # ** your code here**\n",
    "\n",
    "# plot clusters\n",
    "plt.figure(\"More clusters\",figsize=(7,5))\n",
    "plt.scatter(X[:,0],X[:,1],color=\"blue\",marker='o',facecolors='none')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Question 4: **</font> \n",
    "- Call \"K_means_multi_run\" function to calculate \"centroid_min\", \"clust_x_min\" and \"Jmin\".\n",
    "- Add the value of minimum error \"Jmin\" to the \"error_list\".\n",
    "- From the graph could you deduce the best number of cluster?  \n",
    "\n",
    "**Warning:** This block of code may take 1 to 2 minutes to run. Please be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=X.shape[0]\n",
    "K_max=10\n",
    "error_list=[]\n",
    "\n",
    "# initialize some variable\n",
    "clust_x = np.zeros((m,),dtype=int)\n",
    "clust_x_min = np.zeros((m,),dtype=int)\n",
    "\n",
    "for k in range(2,K_max):\n",
    "    centroid = np.zeros((k,X.shape[1]))\n",
    "    centroid_min = np.zeros((k,X.shape[1]))\n",
    "    Jmin=np.inf \n",
    "\n",
    "    centroid_min,clust_x_min,Jmin =  # ** your code here**\n",
    "\n",
    "    # ** your code here**\n",
    "    \n",
    "\n",
    "print(\"Clustering error for different value of K are \",error_list)\n",
    "plt.figure(\"clustering error vs number of cluster K\",figsize=(7,5))\n",
    "plt.plot(np.arange(2,K_max),error_list)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
