{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8: K-Nearest Neighbors Classifier\n",
    "\n",
    "In this session, we illustrate how well accuracy measure evaluate the performance of a classifier on the case of skewed class where the number of sample on a given class is very big compared to size of other classes. Then, present more robust measurement like \"**precision**\", \"**recall**\" and \"**F1-score**\" to evaluate performance a classifier.\n",
    "\n",
    "In the second part, we will implement a **K-nearest classifier**. It is a simple classifier but it may be efficient to resolve several classification problem. Then, we will assess our classifier with the new explored measurement.\n",
    "\n",
    "## Skewed Class\n",
    "In this part, we will work with [breast cancer](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html) dataset from sklearn library. It contains 30 quantitative features and one target with two labels (0:malignant / 1:benign). For this example, we will only use \"mean radius\" of tumor feature and we will also discard some sample to make dataset classes skewed. Then, we will calculate the accuracy of \"Naive_Classifier\" that predict always 0 or 1. Finally, we will present the new measurements given above.\n",
    "\n",
    "#### Confusion matrix\n",
    "The confusion matrix is a specific table layout that allows visualization of the performance/error of a classification algorithm. Each row of the matrix represents the number of samples in each predicted class while each column represents the number of samples in each actual class.\n",
    "![confusion_matrix](confusion_matrix.png)\n",
    "\n",
    "- <font color=\"green\">**TN (True Negative)**</font>**:** Number of sample predicted 0 (**Negative**) and they are actually in negative class 0 (**True** prediction). Also known as \"Correct rejection\"\n",
    "- <font color=\"red\">**FN (False Negative)**</font>**:** Number of sample predicted 0 (**Negative**) and they are actually in positive class 1 (**False** prediction). Also known as \"Miss\"\n",
    "- <font color=\"red\">**FP (False Positive)**</font>**:** Number of sample predicted 1 (**Positive**) and they are actually in negative class 0 (**False** prediction). Also known as \"False alarm\"\n",
    "- <font color=\"green\">**TP (True Positive)**</font>**:** Number of sample predicted 1 (**Positive**) and they are actually in positive class 1 (**True** prediction). Also known as \"Hit\"\n",
    "\n",
    "#### Precision\n",
    "Precision or positive predictive value is the fraction of the true positive prediction over all positive prediction (true and false ones). It reflect how confident is the classifier when detecting a positive sample. It is given by the following formulas:\n",
    "$$precision=\\frac{TP}{TP+FP}$$\n",
    "Therefore, higher precision imply less false alarm (FP).\n",
    "\n",
    "#### Recall\n",
    "Recall or sensitivity is the fraction of the true positive prediction over all actual positive samples. It reflect how confident is the classifier when rejecting a sample. It is given by the following formulas:\n",
    "$$recall=\\frac{TP}{TP+FN}$$\n",
    "Therefore, higher recall imply less positive sample non-detected (FN).  \n",
    "\n",
    "In general, there is a trade-off between precision and recall. For example, with a logistic classifier if we try to increase the decision threshold (when the probability exceed this value we predict 1 as class)  to enhance precision the recall will decrease and vice versa as illustrated in the precision-recall curve below.\n",
    "\n",
    "![precision vs recall curve](P_vs_R.png)\n",
    "\n",
    "#### F1-score\n",
    "Because of the trade-off between precision and recall we try other measurement, the F1-score, to evaluate the performance of the classifier. Therefore, we could use the F1-score as single value criteria to compare and choose between two models. This measurement reflect how well precision and recall. For instance, if both precision and recall are high the F1-score is high and vice versa.\n",
    "\n",
    "The F1-score is given by the following formulas:\n",
    "$$F_1=2\\times \\frac{precision\\times recall}{precision+recall}$$\n",
    "\n",
    "<font color=\"blue\">**Question 1: **</font>\n",
    "- Load cancer dataset using [\"load_breast_cancer\"](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html) function and explore it (what are feature_names/target_names/size/type...?). \n",
    "- Complete \"fit\" function in \"Naive_Classifier\" class in order to assign to \"self.prediction\" variable the most existing class (0 or 1) in \"target\" array.\n",
    "- Call \"predict\" and \"score\" function from \"Naive_Classifier\" class to calculate \"y_pred\" and \"accuracy\" variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import warnings\n",
    "\n",
    "# load breast cancer dataset\n",
    "cancer_database =  # ** your code here**\n",
    "\n",
    "# print some information about the dataset\n",
    "print(type(cancer_database))\n",
    "print(cancer_database.target_names) #(0:malignant/1:benign)\n",
    "#print(cancer_database.feature_names)\n",
    "#print(cancer_database.DESCR)\n",
    "\n",
    "# discard some samples\n",
    "index=np.logical_or(cancer_database.data[:,0]>25,cancer_database.target==1)\n",
    "X=cancer_database.data[index,:]\n",
    "y=cancer_database.target[index,np.newaxis]\n",
    "\n",
    "# number of malignant/benign tumor on the resulting dataset\n",
    "nbr_begnin = np.sum(y==1)  \n",
    "nbr_malignant = np.sum(y==0)\n",
    "print(\"The number of  benign tumor: \",nbr_begnin)\n",
    "print(\"The number of  malignant  tumor: \",nbr_malignant)\n",
    "\n",
    "# implement Naive classifier\n",
    "class Naive_Classifier():\n",
    "    def __init__(self, default_prediction=None):\n",
    "        if (default_prediction!=None):\n",
    "            self.prediction = default_prediction\n",
    "    def fit(self,data,target):\n",
    "        self.m=data.shape[0]\n",
    "        self.n=data.shape[1]\n",
    "        if (target.shape[0]!=self.m):\n",
    "            raise ValueError('The number of sample in the data and in the target are not equal!')\n",
    "        # ** your code here**\n",
    "\n",
    "    def predict(self,X):\n",
    "        return self.prediction*np.ones((X.shape[0],1))\n",
    "    def score(self,predict,target):\n",
    "        if (predict.shape[0]!=target.shape[0]):\n",
    "            #warnings.showwarning('The number of sample in the prediction and in the target are not equal!',UserWarning,sys.stderr,lineno='return (predict==target).sum()/target.shape[0]*100')\n",
    "            raise ValueError('The number of sample in the prediction and in the target are not equal!')\n",
    "        return (predict==target).sum()/target.shape[0]*100\n",
    "\n",
    "# train and predict with naive classifier\n",
    "naiv_clf=Naive_Classifier()\n",
    "naiv_clf.fit(X,y)\n",
    "y_pred =  # ** your code here**\n",
    "accuracy =   # ** your code here**\n",
    "print(\"The accuracy of the Naive Classifier is %.2f\"%accuracy,\"% !!!\")\n",
    "\n",
    "# plot dataset\n",
    "plt.figure(\"cancer database\",figsize=(9,5))\n",
    "plt.scatter(X[(y==1)[:,0],0],y[y==1],label='begnin',color=\"green\")\n",
    "plt.scatter(X[(y==0)[:,0],0],y[y==0],label='malignant', color=\"red\")\n",
    "plt.legend(loc='lower left', shadow=True, fontsize='x-large')\n",
    "plt.xlabel('mean radius')\n",
    "plt.ylabel('malignant/begnin class')\n",
    "plt.yticks([0,1])\n",
    "plt.title('mean radius vs class')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Question 2: **</font>\n",
    "- Calculate the following quantities FP (False Positive), FN (False Negative) and TN (True Negative).\n",
    "**Hint:** You can use an expression with [\"logical_and\"](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.logical_and.html) function similarly to the calculation of TP (True Positive).\n",
    "- Calculate \"precision\", \"recall\" and \"F1_score\" according to expressions given above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn import metrics\n",
    "\n",
    "# calculate different metrics\n",
    "tp=np.logical_and(y==1,y_pred==1).sum()\n",
    "fp =  # ** your code here**\n",
    "fn =  # ** your code here**\n",
    "tn =  # ** your code here**\n",
    "\n",
    "precision =  # ** your code here**\n",
    "recall =   # ** your code here**\n",
    "F1_score =  # ** your code here**\n",
    "\n",
    "\n",
    "print(\"The calculated confusion matrix:\\n\", np.array([[tn,fp],[fn,tp]]))\n",
    "print(\"The calculated precision: %.3f\"%(100*precision),\"%\")\n",
    "print(\"The calculated recall: %.3f\"%(100*recall),\"%\")\n",
    "print(\"The calculated F1_score: %.3f\"%(100*F1_score),\"%\")\n",
    "print()\n",
    "\n",
    "# use defined metrics from sklearn library\n",
    "print(\"The sklearn confusion matrix:\\n\",metrics.confusion_matrix(y, y_pred))\n",
    "print(\"The sklearn precision:\",metrics.precision_score(y, y_pred))\n",
    "print(\"The sklearn recall:\",metrics.recall_score(y, y_pred))\n",
    "print(\"The sklearn F1_score:\",metrics.f1_score(y, y_pred))\n",
    "print(\"The sklearn classification report:\\n\",metrics.classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors\n",
    "\n",
    "The K-Nearest Neighbors algorithm is simple method used mainly for classification problem but there is also some version for regression problem. The main idea is to determine the most similar (closest) samples from the dataset to the new sample to predict. Then, we predict a value close and similar to the value of nearest neighbors from the dataset.  \n",
    "\n",
    "In regression problem we determine ,for example, the 5 nearest sample (K=5) to our sample. Then, we predict as output the average  or weighted average of 5 nearest sample. There is several way to determine the weight. Some of them use constant weight. Other method use weight that inversely vary regarding the distance between our sample and neighbor and they use some kernel like \"linear\", \"Gaussian\"â€¦ to select these weights. \n",
    "\n",
    "While for Classification problem, we select the K-nearest neighbors. Then, we make a vote between neighbors to decide which label (class) to predict for our sample. In this case, K (number of neighbors) shouldn't be a multiple of number of class to avoid ambiguous vote. We could also use weighted vote regarding to the distance between neighbors and the sample to predict.\n",
    "\n",
    "In this part, we will implement a K-nearest neighbors algorithm for classification problem. We will use euclidean distance to determine nearest neighbors. Then, we will use majority vote to decide which class to predict.\n",
    "\n",
    "<font color=\"blue\">**Question 3: **</font>\n",
    "- Load data from \"data_3.txt\" file. (use [loadtxt](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.loadtxt.html) function from numpy library).\n",
    "- Implement the \"euclidean_dist\" function that calculate the euclidean distance (norm L2: sum of square) between two vectors.\n",
    "- Complete the \"KNN\" function:\n",
    "     - You should use \"euclidean_dist\" to calculate the distance matrix \"D\" that contains distance between the \"ith\" sample to predict in the array \"x\" and each sample in the training set \"data_x\".\n",
    "     - Then, you may use [argsort](https://docs.scipy.org/doc/numpy/reference/generated/numpy.argsort.html) function to determine indices that sort the matrix \"D\" among column and apply these indices to sort labels vector \"data_y\" from the nearest to the farthest neighbor.\n",
    "     - Finally, you should call \"Vote\" function on the resulting sorted label vector to determine the prediction (most appeared class on the K nearest neighbors to the \"ith\" sample in \"x\" array)\n",
    "- Implement \"Vote\" function that take a matrix \"M\" of labels of neighborhood and the number \"k\" of neighbors to consider in the vote. Then, for each column it determine the most appeared class on the K nearest neighbors (K first lines) this is the predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# load data\n",
    "data =    # ** your code here** \n",
    "train_data, test_data = train_test_split(data, test_size=0.25, random_state=0)\n",
    "print(\"The size of training set is:\",train_data.shape)\n",
    "print(\"The size of test set is:\",test_data.shape)\n",
    "\n",
    "# extract data\n",
    "X_train=train_data[:,:2]\n",
    "y_train=train_data[:,2,np.newaxis].astype(int)   \n",
    "X_test=test_data[:,:2]\n",
    "y_test=test_data[:,2,np.newaxis].astype(int) \n",
    "\n",
    "def euclidean_dist(x1,x2):\n",
    "    # ** your code here** \n",
    "    \n",
    "    return \n",
    "\n",
    "def KNN(data_x,x,data_y,k):\n",
    "    # data_x: training set point\n",
    "    # x: points to predict\n",
    "    # data_y: training set labels\n",
    "    # k: number of nearest neighbors to concider\n",
    "    # return: predition for each sample on \"x\" array\n",
    "    \n",
    "    pred=np.zeros((x.shape[0],1),dtype=int)\n",
    "    for i in range(x.shape[0]):\n",
    "        D=   # ** your code here** \n",
    "        # ** your code here** \n",
    "        pred[i,0] = # ** your code here** \n",
    "    return pred\n",
    "\n",
    "def Vote(M,k):\n",
    "    # M: neighborhood matrix it contains on each columns labels of the nearest neighbor in order.\n",
    "    # return: predicted label for each columns (samples)\n",
    "    # ** your code here** \n",
    "    \n",
    "    return \n",
    "\n",
    "# number of nearest neighbors to concider\n",
    "K=31\n",
    "\n",
    "# try the K-nearest neighbors classifier\n",
    "x_try = np.array([[-0.295,0.4],[-0.2,0.4],[0.2,-0.2]])\n",
    "y_try_pred = KNN(X_train,x_try,y_train,K)\n",
    "print(\"The predictions for stared point on the graph are:\",y_try_pred[:,0]==1)\n",
    "\n",
    "y_test_pred = KNN(X_train,X_test,y_train,K)\n",
    "print(\"Test accuracy =\",(y_test_pred==y_test).sum()*100/y_test.shape[0],\"%\")\n",
    "\n",
    "# calculate the mesh grid for contour plot\n",
    "u1=np.linspace(-0.6,0.3,100)\n",
    "u2=np.linspace(-0.8,0.6,100)\n",
    "u1, u2 = np.meshgrid(u1, u2)\n",
    "X3=np.concatenate((u1[...,np.newaxis],u2[...,np.newaxis]),axis=-1)\n",
    "X3bis=X3.reshape((X3.shape[0]*X3.shape[1],X3.shape[2]))\n",
    "Zbis =  KNN(X_train,X3bis,y_train,K)\n",
    "Z=Zbis.reshape((X3.shape[0],X3.shape[1]))\n",
    "\n",
    "# plot data and boundary\n",
    "plt.figure(\"K-nearest neighbors boundary\",figsize=(9,5))\n",
    "fail_train=plt.scatter(train_data[:,0][train_data[:,2]==0], train_data[:,1][train_data[:,2]==0],  color='gray',label='fail')\n",
    "succ_train=plt.scatter(train_data[:,0][train_data[:,2]==1], train_data[:,1][train_data[:,2]==1],  color='gray',marker='+',s=80, label='success')\n",
    "fail_test=plt.scatter(test_data[:,0][test_data[:,2]==0], test_data[:,1][test_data[:,2]==0],  color='red',label='fail')\n",
    "succ_test=plt.scatter(test_data[:,0][test_data[:,2]==1], test_data[:,1][test_data[:,2]==1],  color='green',marker='+',s=80, label='success')\n",
    "plt.scatter(x_try[:,0],x_try[:,1],color=\"black\",marker='*',s=70)\n",
    "ctr = plt.contour(u1, u2, Z,1,colors=\"blue\")\n",
    "plt.xlabel('x_1')\n",
    "plt.ylabel('x_2')\n",
    "boundary = Rectangle((0, 0), 3, 4, fc=\"w\", fill=False, edgecolor=\"b\", linewidth=1)\n",
    "plt.legend([boundary,fail_test,succ_test,fail_train,succ_train], (\"decision boundary\",\"test data (fail)\",\"test data (success)\",\"train data (fail)\",\"train data (success)\"),loc='best')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
