{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Linear Regression\n",
    "\n",
    "In this practice session, you are invited to train a linear regression model using gradient descent method. After the learning phase, your model should predict house prices in the region of *\"Ile-de-France\"* given their areas (in m²) and their numbers of rooms.\n",
    "\n",
    "We will also enhace the perfomence of the learning algorithm using different implementation techniques like vectorization and features normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and load data\n",
    "Import **numpy** library that support matrix operation and **matplotlib** library for plotting data.  \n",
    "<font color=\"blue\">**Question 1: **</font>The *\"house.csv\"* file contains 3 columns that represent the area, the number of rooms and the price of 600 houses (one per row). \n",
    "- Open this file with a file editor to understand more the data. \n",
    "- Load the data in \"house_data\" variable and check its size.  \n",
    "**Hint:** You could use [loadtxt](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.loadtxt.html) function from numpy library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "house_data=# **your code here**\n",
    "\n",
    "# you could also check the size of the data by printing the shape of house_data array\n",
    "# **your code here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression with 1 feature (house area)\n",
    "\n",
    "In this first part, we will train a linear model for house price prediction using only one feature the house area. We will start by implementing a cost function and the gradient of this cost function. Then, we will implement the gradient descent algorithm that minimizes this cost function and determine the linear model parameter $\\theta$ in the equation $h_\\theta(x)=\\theta_1 x$.  \n",
    "\n",
    "<font color=\"blue\">**Question 2: **</font> \n",
    "- Determine the number of samples \"m\" from the input data \"house_price\".\n",
    "- Extract the house area and price columns respectively in \"x_1\" and \"y\" arrays to visualize them.  \n",
    "**Hint:** The shape of \"x_1\" and \"y\" arrays should be (m,1) for the following questions and not (m,). You could use [newaxis numpy](https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html#basic-slicing-and-indexing) object to add a new axis of length one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "m = #**your code here** # number of sample\n",
    "n = 1                   # number of features\n",
    "x_1 = # **your code here**\n",
    "X = x_1\n",
    "y = # **your code here**\n",
    "\n",
    "#Visualiaze data\n",
    "plt.figure(\"Visualize house data\",figsize=(9,5))\n",
    "plt.scatter(x_1, y,  color='black')\n",
    "plt.xlabel('house area (m²)')\n",
    "plt.ylabel('house price (1000€)')\n",
    "plt.title('house area vs price')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost function\n",
    "The cost function we will use for this linear model training is the **Mean Squared Error (MSE)**: $$cost\\_func(x) = \\frac{1}{2~m} \\sum_{i=1}^{m}{(h_\\theta(x_i) - y_i)^2}$$\n",
    "\n",
    "<font color=\"blue\">**Question 3: **</font> \n",
    "- Implement the \"cost_func\" function that evaluate and return the previous equation of MSE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost_func(theta):\n",
    "    J=0\n",
    "    # **your code here**\n",
    "    \n",
    "    return J\n",
    "\n",
    "\n",
    "theta_init=np.array([[-3]],dtype=float)\n",
    "cost = cost_func(theta_init)\n",
    "print(\"Cost function for theta={0} is : {1}\".format(theta_init[:,0],cost))\n",
    "\n",
    "theta_1 = np.linspace(-5,12.5,100)\n",
    "J=[] #empty list\n",
    "for i in range(theta_1.shape[0]):\n",
    "    J.append(cost_func(np.array([[theta_1[i]]])))\n",
    "    \n",
    "# MSE cost function plot (convex function)\n",
    "plt.figure('Cost Function J(theta)',figsize=(9,5))\n",
    "plt.plot(theta_1, J,  color='blue')\n",
    "plt.scatter(theta_init[0,0],cost,marker='o',s=50,color=\"magenta\")\n",
    "plt.annotate(\"theta_init\", (0.95*theta_init[0,0],1.05*cost))\n",
    "plt.xlabel('Theta_1')\n",
    "plt.ylabel('Cost function')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient of cost function\n",
    "The gradient of the Mean Squared Error cost function is calculated as following: $$\\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i=1}^{m}{(h_\\theta(x_i) - y)~x_j} ~~for~ j=0\\dots n-1$$\n",
    "<font color=\"blue\">**Question 4: **</font> \n",
    "- Implement the \"grad_cost_func\" function that evaluates the gradient of the cost function at the point theta considering the $j^{th}$ component as given on the previous equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import exp, fabs,atan\n",
    "def grad_cost_func(theta,j):\n",
    "    grad=np.zeros((1,1))\n",
    "    # **your code here**\n",
    "\n",
    "    return grad\n",
    "    \n",
    "grad=grad_cost_func(theta_init,0)\n",
    "print(\"Gradient for theta={0} is : {1}\".format(theta_init[:,0],grad[:,0]))\n",
    "\n",
    "#Visualize the gradient direction on the cost function plot\n",
    "plt.figure('Gradient Vector Of Cost Function J(theta)',figsize=(9,5))\n",
    "plt.plot(theta_1, J,  color='blue')\n",
    "plt.scatter(theta_init[0,0],cost,marker='o',s=50,color=\"magenta\")\n",
    "plt.annotate(\"theta_init\", (0.95*theta_init[0,0],1.05*cost))\n",
    "plt.quiver(theta_init[0,0],cost,1/(1+exp(grad[0,0]))-0.5,(1/(1+exp(grad[0,0]))-0.5)*grad[0,0],color='red',scale=0.5,scale_units='xy',angles='xy')\n",
    "plt.xlabel('Theta_1')\n",
    "plt.ylabel('Cost function')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient descent algorithm\n",
    "The gradient descent algorithm is a downhill iterative optimization method that uses the gradient direction as descending direction on each step to reach a local minimum. For a convex function, such as the MSE cost function, the gradient descent is guaranteed to reach a global minimum.  \n",
    "The update equation of the optimization parameter $\\theta$ is given by: $$\\theta_j=\\theta_j-\\alpha \\frac{\\partial J(\\theta)}{\\partial \\theta_j} ~~for~ j=0\\dots n-1$$\n",
    "Where $\\alpha:$ represents the step or the learning rate.\n",
    "\n",
    "<font color=\"blue\">**Question 5: **</font> \n",
    "- Implement the \"grad_descent\" algorithm that updates, iteratively, the parameter vector theta  according to the previous equation.  \n",
    "- Call \"grad_descent\" function to calculate \"theta_opt\". you could use \"max_iteration\" of 1000 and \"alpha\" equal to 0.0001.  \n",
    "- Use the calculated \"theta_opt\" to estimate the price of a house with 330 m² area.  \n",
    "\n",
    "<font color=\"blue\">**Question 5' (optional homework): **</font>  \n",
    "Note that calculation time taken by gradient descent is in the range of a second. In order to enhance the performance of our algorithm, we could re-write \"cost_func\", \"grad_cost_func\" and \"grad_descent\" functions with a vectorized implementation.  \n",
    "**Hint:** Use direct operation on arrays like $+,-, \\times \\dots$ You could also use [dot product](https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html), [transpose](https://docs.scipy.org/doc/numpy/reference/generated/numpy.transpose.html) and [sum](https://docs.scipy.org/doc/numpy-1.12.0/reference/generated/numpy.sum.html) functions to calculate sums along vectors rather than using for loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def grad_descent(grad_func, theta0,max_iter=100,alpha=0.0001):\n",
    "    theta=theta0.copy()\n",
    "    # **your code here**\n",
    "\n",
    "    return theta\n",
    "\n",
    "start_time = time.time()\n",
    "theta_opt=     # **your code here**\n",
    "print(\"The gradient descent algorithm takes {:.4f} s to finish calculation\".format(time.time()-start_time))\n",
    "prediction=np.dot(X,theta_opt)\n",
    "\n",
    "print(\"The optimal value of theta that minimizes the cost function is: \",theta_opt[:,0])\n",
    "print(\"Final error = \",np.sum((prediction-y)**2)/(2*m))\n",
    "\n",
    "area = 330\n",
    "price =     # **your code here**\n",
    "print(\"The predicted price of a {0} m² house is: {1} k€\".format(area,price[0,0]))\n",
    "\n",
    "plt.figure('Regression Model')\n",
    "plt.scatter(x_1, y,  color='black')\n",
    "plt.plot(np.sort(x_1,axis=0),prediction[np.argsort(x_1,axis=0),0], color='red', linewidth=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression with 2 features (house area + bias term)\n",
    "\n",
    "In this part, we will train a linear model for house price prediction using the house area and the bias term that represents the constant term (y-intercept) in the linear model equation $~h_\\theta(x)=\\theta_1 x+\\theta_0$.\n",
    "\n",
    "<font color=\"blue\">**Question 6: **</font> \n",
    "- Build the matrix X with shape (m,2) that represents 2 features: a column of ones that represents the bias term and a column of house area.  \n",
    "**Hint:** You could use numpy [concatenate](https://docs.scipy.org/doc/numpy/reference/generated/numpy.concatenate.html) function (put two columns or array together).\n",
    "- Change the value of \"n\" to be equal to the number of features (number of columns of matrix X equal to 2 in this example).  \n",
    "- Make all needed modification in \"cost_func\", \"grad_cost_func\" and \"grad_descent\" functions if your implementation was not generalizable for any number of features n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d.axes3d import*\n",
    "from matplotlib import cm\n",
    "from math import copysign\n",
    "\n",
    "X =     # **your code here**\n",
    "n =     # **your code here**\n",
    "    \n",
    "theta_init=np.array([[0],[-3]],dtype=float)\n",
    "cost = cost_func(theta_init)\n",
    "print(\"Cost function for theta={0} is : {1}\".format(theta_init[:,0],cost))\n",
    "\n",
    "grad=grad_cost_func(theta_init)\n",
    "print(\"Gradient for theta={0} is : {1}\".format(theta_init[:,0],grad[:,0]))\n",
    "\n",
    "theta_0 = np.linspace(100,300,100) # you could use also: theta_0 = np.arange(100, 300, 2)\n",
    "theta_1 = np.linspace(-1,5,120)    # you could use also: theta_1 = np.arange(-1, 5, 0.05)\n",
    "\n",
    "\n",
    "theta_0, theta_1 = np.meshgrid(theta_0, theta_1)\n",
    "\n",
    "Theta=np.concatenate((theta_0[:,:,np.newaxis],theta_1[:,:,np.newaxis]),axis=-1)\n",
    "Z =  1/(2*m)*np.sum((np.dot(Theta,X.transpose())-np.tile(y[np.newaxis,np.newaxis,:,0],(*theta_0.shape,1)))**2,axis=-1)\n",
    "\n",
    "print(\"Minimum value of the cost function detected on the plot: \",np.min(Z))\n",
    "print(\"Value of theta_0, theta_1 that minimizes the cost function: \",theta_0[np.argmin(np.min(Z,axis=1)),np.argmin(np.min(Z,axis=0))],theta_1[np.argmin(np.min(Z,axis=1)),np.argmin(np.min(Z,axis=0))])\n",
    "\n",
    "\n",
    "\n",
    "fig=plt.figure('Contour and Surface Plots',figsize=(9,4))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ctr = ax.contour(theta_0, theta_1, Z)\n",
    "ax.clabel(ctr, inline=1, fontsize=10)\n",
    "ax.set_title('Contour Plot')\n",
    "ax.set_xlabel('theta_0')\n",
    "ax.set_ylabel('theta_1')\n",
    "\n",
    "ax=fig.add_subplot(1, 2, 2,projection='3d')\n",
    "ax.plot_surface(theta_0,theta_1,Z,rstride=1,cstride=1,cmap=cm.jet,linewidth=1,antialiased=True)\n",
    "ax.set_title('Surface Polt')\n",
    "ax.set_xlabel('theta_0')\n",
    "ax.set_ylabel('theta_1')\n",
    "ax.set_zlabel('Cost Funtion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Question 7: **</font> \n",
    "- Use the calculated \"theta_opt\" of the new model to estimate the price of a house with 330 m² area.  \n",
    "\n",
    "We note that even with a bias term our model is still start from origin (0,0) and the bias weight $\\theta_0$ is too small. This is because the values of second feature house area are big (the mean is about 100) compared to the bias feature (equals 1). Hence, the cost function is more sensible to the variation of $\\theta_1$ (weight of house area feature) and then $\\theta_0$ will not move a lot from its initial value (which is 0 in our case).\n",
    "\n",
    "<font color=\"blue\">**Question 8: **</font> \n",
    "- Try the feature normalization technique on the house area feature to enhance the convergence of the model. You should modify the \"X\" matrix in the previous code block and re-execute the code. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "theta_opt=grad_descent(grad_cost_func,theta_init,alpha=0.01,max_iter=1000)\n",
    "prediction=np.dot(X,theta_opt)\n",
    "\n",
    "print(\"The optimal value of theta that minimizes cost function is: \",theta_opt[:,0])\n",
    "print(\"Final error = \",np.sum((prediction-y)**2)/(2*m))\n",
    "\n",
    "area = 330\n",
    "price =     # **your code here**\n",
    "print(\"The predicted price of a {0} m² house is: {1} k€\".format(area,price[0,0]))\n",
    "\n",
    "plt.scatter(x_1, y,  color='black')\n",
    "plt.plot(np.sort(x_1,axis=0),prediction[np.argsort(x_1,axis=0),0], color='red', linewidth=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression with 3 features (house area + number of rooms + bias term)\n",
    "\n",
    "In this part, we will train a linear model for house price prediction using the house area, number of rooms and the bias term that represents the constant term in the linear model equation $~h_\\theta(x)=\\theta_2 x_2+\\theta_1 x_1+\\theta_0$.\n",
    "\n",
    "<font color=\"blue\">**Question 9: **</font>\n",
    "- Build the matrix X with shape (m,3) that represents 3 features: a column of ones that represents the bias term, a column of house area and a column of number of rooms. \n",
    "- Change the value of \"n\" to be equal to the number of features (number of columns of matrix X equal to 3 in this example).\n",
    "- Use the calculated \"theta_opt\" of the new model to estimate the price of a house with 330 m² area and 5 rooms. Compared to the previous model which predict better house prices?\n",
    "\n",
    "You could also try to add other feature columns to the matrix X like $area^2$ or $area^{0.5}\\dots~$ and see the effect on the model and the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "x_1 = house_data[:,0,np.newaxis]\n",
    "x_2 = house_data[:,1,np.newaxis]\n",
    "X =      # **your code here**\n",
    "n =      # **your code here**\n",
    "\n",
    "theta0=np.array([[0],[-3],[0]],dtype=float)\n",
    "cost = cost_func(theta0)\n",
    "print(\"Cost function for theta={0} is : {1}\".format(theta0[:,0],cost))\n",
    "\n",
    "grad=grad_cost_func(theta0)\n",
    "print(\"Gradient for theta={0} is : {1}\".format(theta0[:,0],grad[:,0]))\n",
    "\n",
    "theta_opt=grad_descent(grad_cost_func,theta0,alpha=0.03,max_iter=250)\n",
    "prediction=np.dot(X,theta_opt)\n",
    "print(\"The optimal value of theta that minimizes cost function is: \",theta_opt[:,0])\n",
    "print(\"Final error = \",np.sum((prediction-y)**2)/(2*m))\n",
    "\n",
    "area = 330\n",
    "nbr_room = 5\n",
    "price =      # **your code here**\n",
    "print(\"The predicted price of a {0} m² house with {1} rooms is: {2} k€\".format(area,nbr_room,price[0,0]))\n",
    "\n",
    "fig=plt.figure('Linear model plot')\n",
    "plt.scatter(x_1, y,  color='black')\n",
    "plt.plot(np.sort(x_1,axis=0),prediction[np.argsort(x_1,axis=0),0], color='red', linewidth=3)\n",
    "\n",
    "\n",
    "fig=plt.figure('Surface plot')\n",
    "ax=Axes3D(fig)\n",
    "ax.scatter(x_1,x_2,y)\n",
    "\n",
    "x1 = np.linspace(0,400,400) \n",
    "x2 = np.arange(13)\n",
    "x1, x2 = np.meshgrid(x1, x2)\n",
    "\n",
    "X3=np.concatenate((np.ones((*x1.shape,1)),(x1[:,:,np.newaxis]-x_1.mean())/x_1.std(),(x2[:,:,np.newaxis]-x_2.mean())/x_2.std()),axis=-1)\n",
    "Z =  np.dot(X3,theta_opt)[:,:,0]\n",
    "ax.plot_surface(x1,x2,Z,rstride=1,cstride=1,cmap=cm.jet,linewidth=1,antialiased=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
